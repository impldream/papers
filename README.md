* [Papers](#Papers)
    * [Face-detection/recognition/reconstruction](#Face-detection/recognition/reconstruction)
    * [Object-detection/segmentation/tracking](#Object-detection/segmentation/tracking)
    * [Meta-learning/Few-shot-learning/one-shot-learning](#Meta-learning/Few-shot-learning/one-shot-learning)
    * [Image-processing](#Image-processing)
    * [OCR](#OCR)
* [DataSets](#DataSets)

# Papers
## Face-detection/recognition/reconstruction
+ [Towards Universal Representation Learning for Deep Face Recognition](https://arxiv.org/abs/2002.11841) [CVPR2020]   
+ [Suppressing Uncertainties for Large-Scale Facial Expression Recognition](https://arxiv.org/abs/2002.10392) [[code](https://github.com/kaiwang960112/Self-Cure-Network)] [CVPR2020]    
+ [Face X-ray for More General Face Forgery Detection](https://arxiv.org/pdf/1912.13458.pdf) [CVPR2020]  
+ [CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition](https://arxiv.org/abs/2004.00288) [[code](https://github.com/HuangYG123/CurricularFace)] [CVPR2020]  
+ [Learning Meta Face Recognition in Unseen Domains](https://arxiv.org/abs/2003.07733) [[code](https://github.com/cleardusk/MFR)] [CVPR2020]  
+ [Searching Central Difference Convolutional Networks for Face Anti-Spoofing](https://arxiv.org/abs/2003.04092) [[code](https://github.com/ZitongYu/CDCN)] [CVPR2020]  
+ [Rotate-and-Render: Unsupervised Photorealistic Face Rotation from Single-View Images](https://arxiv.org/abs/2003.08124) [[code](https://github.com/Hangz-nju-cuhk/Rotate-and-Render)] [CVPR2020]  
+ [AvatarMe: Realistically Renderable 3D Facial Reconstruction "in-the-wild"](https://arxiv.org/abs/2003.13845) [[code](https://github.com/lattas/AvatarMe)] [CVPR2020]  
+ [FaceScape: a Large-scale High Quality 3D Face Dataset and Detailed Riggable 3D Face Prediction](https://arxiv.org/abs/2003.13989) [[code](https://github.com/zhuhao-nju/facescape)] [CVPR2020]  
## Object-detection/segmentation/tracking
**2D**

+ [Mask RCNN](https://arxiv.org/abs/1703.06870)           [ [code](https://github.com/matterport/Mask_RCNN)]  
+ [SSD](https://arxiv.org/abs/1512.02325)                     [[code](https://github.com/balancap/SSD-Tensorflow)]  
+ [yolo3](https://arxiv.org/abs/1804.02767)                    [[code](https://github.com/qqwweee/keras-yolo3)]  
+ [EfficientDet](https://arxiv.org/pdf/1911.09070.pdf)  [[code](https://github.com/google/automl/tree/master/efficientdet)]   
+ [Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection](https://arxiv.org/abs/1912.02424)    [[code](https://github.com/sfzhang15/ATSS)]    [CVPR2020]   
+ [CenterMask : Real-Time Anchor-Free Instance Segmentation](https://arxiv.org/abs/1911.06667) [[code](https://github.com/youngwanLEE/CenterMask)] [CVPR2020]
+ [PolarMask: Single Shot Instance Segmentation with Polar Representation](https://arxiv.org/abs/1909.13226) [[code](https://github.com/xieenze/PolarMask)] [CVPR2020]    
+ [ResNeSt: Split-Attention Networks](https://arxiv.org/abs/2004.08955) [[code](https://github.com/zhanghang1989/ResNeSt)] [CVPR2020]  

**3D**  

+  [PointNet](https://arxiv.org/abs/1612.00593)    [[code](https://github.com/charlesq34/pointnet)]   
+  [PointNet++](https://arxiv.org/abs/1706.02413)    [[code](https://github.com/charlesq34/pointnet2)]   
+  [VoxelNet](http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html)    [[code](https://github.com/qianguih/voxelnet)]   
+ [D3Feat: Joint Learning of Dense Detection and Description of 3D Local Features](https://arxiv.org/abs/2003.03164) [[code](https://github.com/XuyangBai/D3Feat)] [CVPR2020]  
+ [Cascaded Refinement Network for Point Cloud Completion](https://arxiv.org/abs/2004.03327) [[code](https://github.com/xiaogangw/cascaded-point-completion)] [CVPR2020]   
+ [PointAugment: an Auto-Augmentation Framework for Point Cloud Classification](https://arxiv.org/abs/2002.10876) [[code](https://github.com/liruihui/PointAugment/)] [CVPR2020]   

## Meta-learning/Few-shot-learning/one-shot-learning
+ [Few-shot Object Detection via Feature Reweighting](https://arxiv.org/pdf/1812.01866.pdf) [ICCV2019]  
+ [A Closer Look at Few-shot Classification](https://arxiv.org/abs/1904.04232) [[code](https://github.com/wyharveychen/CloserLookFewShot)] [ICLR]  
+ [Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector](https://arxiv.org/abs/1908.01998)    [CVPR2020]  
+ [A New Meta-Baseline for Few-Shot Learning](https://arxiv.org/abs/2003.04390) [[code](https://github.com/cyvius96/few-shot-meta-baseline)] [CVPR2020]   
+ [A Baseline for Few-Shot Image Classification](https://arxiv.org/abs/1909.02729) [ICLR2020]   

## Image-processing
+ [Deep Image Harmonization via Domain Verification](https://arxiv.org/abs/1911.13239) [[code](https://github.com/bcmi/Image_Harmonization_Datasets)] [CVPR2020]

## OCR
+ [ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network](https://arxiv.org/abs/2002.10200) [[code](https://github.com/Yuliang-Liu/bezier_curve_text_spotting,https://github.com/aim-uofa/adet)] [CVPR2020]   
+ [Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection](https://arxiv.org/abs/2003.07493) [[code](https://github.com/GXYM/DRRG)] [CVPR2020]   
+ [UnrealText: Synthesizing Realistic Scene Text Images from the Unreal World](https://arxiv.org/abs/2003.10608)    [[code](https://github.com/Jyouhou/UnrealText/)] [CVPR2020]   
+ [Learn to Augment: Joint Data Augmentation and Network Optimization for Text Recognition](https://arxiv.org/abs/2003.06606) [[code](https://github.com/Canjie-Luo/Text-Image-Augmentation)] [CVPR2020]  


# DataSets

**2D**

+ [CIFAR10 / CIFAR100](http://www.cs.utoronto.ca/~kriz/cifar.html)
+ [kaggle](https://www.kaggle.com/docs/datasets)
+ [Caltech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)
+ [Caltech 256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)
+ [Pascal VOC](https://pjreddie.com/projects/pascal-voc-dataset-mirror/)
+ [Labelme](http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php)
+ [ImageNet](http://image-net.org/)
+ [MS COCO](http://mscoco.org/)
+ [COIL 20](http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php）)
+ [COIL100](http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php)
+ [Google’s Open Images](https://research.googleblog.com/2016/09/introducing-open-images-dataset.html)
+ [Omniglot](https://github.com/brendenlake/omniglot) [meta learning]   

**3D**

+ [NYUv2 RGB-D](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)
+ [Sun RGB-D](http://rgbd.cs.princeton.edu/)
+ [SceneNN](http://www.scenenn.net/)
+ [ScanNetv2 PCL](http://www.scan-net.org/)
+ [SceneNet RGB-D](https://robotvault.bitbucket.io/scenenet-rgbd.html)
+ [Paris-rue-Madame](http://www.cmm.mines-paristech.fr/~serna/rueMadameDataset.html)
+ [iQmulus](http://data.ign.fr/benchmarks/UrbanAnalysis/)
+ [VKITTI](https://europe.naverlabs.com/Research/Computer-Vision/Proxy-Virtual-Worlds/)
+ [Semantic3D](http://www.semantic3d.net/)
+ [Kitti 3D Object](http://www.cvlibs.net/datasets/kitti/eval_object.php)
+ [TUM](https://www.iosb.fraunhofer.de/servlet/is/71820)
+ [KITTI](http://www.cvlibs.net/datasets/kitti/raw_data.php)